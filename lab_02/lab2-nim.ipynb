{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright **`(c)`** 2022 Giovanni Squillero `<squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Lab 3: ES\n",
    "\n",
    "## Task\n",
    "\n",
    "Write agents able to play [*Nim*](https://en.wikipedia.org/wiki/Nim), with an arbitrary number of rows and an upper bound $k$ on the number of objects that can be removed in a turn (a.k.a., *subtraction game*).\n",
    "\n",
    "The goal of the game is to **avoid** taking the last object.\n",
    "\n",
    "* Task2.1: An agent using fixed rules based on *nim-sum* (i.e., an *expert system*)\n",
    "* Task2.2: An agent using evolved rules using ES\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Create the directory `lab2` inside your personal course repository for the course \n",
    "* Put a `README.md` and your solution (all the files, code and auxiliary data if needed)\n",
    "\n",
    "## Notes\n",
    "\n",
    "* Working in group is not only allowed, but recommended (see: [Ubuntu](https://en.wikipedia.org/wiki/Ubuntu_philosophy) and [Cooperative Learning](https://files.eric.ed.gov/fulltext/EJ1096789.pdf)). Collaborations must be explicitly declared in the `README.md`.\n",
    "* [Yanking](https://www.emacswiki.org/emacs/KillingAndYanking) from the internet is allowed, but sources must be explicitly declared in the `README.md`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pprint import pprint, pformat\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *Nim* and *Nimply* classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 3\n",
    "rows = [i * 2 + 1 for i in range(num)]\n",
    "print(rows)\n",
    "print(sum(rows))\n",
    "print(\"<\" + \" \".join(str(_) for _ in rows) + \">\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nim:\n",
    "    # define rules of the game\n",
    "    def __init__(self, num_rows: int, k: int = None) -> None:\n",
    "        self._rows = [i * 2 + 1 for i in range(num_rows)]\n",
    "        self._k = k\n",
    "\n",
    "    def __bool__(self):\n",
    "        return sum(self._rows) > 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    @property  # getter\n",
    "    def rows(self) -> tuple:\n",
    "        return tuple(self._rows)\n",
    "\n",
    "    # applies the move to the game\n",
    "    def nimming(self, ply: Nimply) -> None:  # you have to pass an object of type Nimply\n",
    "        row, num_objects = ply\n",
    "        assert self._rows[row] >= num_objects  # check if there are at least num_objects in the row\n",
    "        assert self._k is None or num_objects <= self._k  # check if the number of objects to be removed is less than k\n",
    "        self._rows[row] -= num_objects  # if everything is ok, remove the objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample (and silly) startegies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_random(state: Nim) -> Nimply:\n",
    "    \"\"\"A completely random move\"\"\"\n",
    "    row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "    num_objects = random.randint(1, state.rows[row])\n",
    "    return Nimply(row, num_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabriele(state: Nim) -> Nimply:\n",
    "    \"\"\"Pick always the maximum possible number of the lowest row\"\"\"\n",
    "    possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "    return Nimply(*max(possible_moves, key=lambda m: (-m[0], m[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_moves = [(r, o) for r, c in enumerate(rows) for o in range(1, c + 1)]\n",
    "print(possible_moves)\n",
    "#remove the first element from possible_moves\n",
    "possible_moves.pop(0)\n",
    "print(max(possible_moves, key=lambda m: (-m[0], m[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive(state: Nim) -> Nimply:\n",
    "    \"\"\"A strategy that can adapt its parameters\"\"\"\n",
    "    genome = {\"love_small\": 0.5}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "tmp = np.array([tuple(int(x) for x in f\"{c:032b}\") for c in rows])\n",
    "# print(rows[1])\n",
    "# print(tmp[2])\n",
    "\n",
    "xor = tmp.sum(axis=0) % 2\n",
    "print(tmp.sum(axis=0))\n",
    "print(xor)\n",
    "\n",
    "print(int(\"\".join(str(_) for _ in xor), base=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def nim_sum(state: Nim) -> int:\n",
    "    # convert the rows to a binary representation in 32 bits\n",
    "    tmp = np.array([tuple(int(x) for x in f\"{c:032b}\") for c in state.rows])\n",
    "\n",
    "    # compute the xor of all the rows\n",
    "    xor = tmp.sum(axis=0) % 2\n",
    "\n",
    "    # convert the xor to an integer\n",
    "    return int(\"\".join(str(_) for _ in xor), base=2)\n",
    "\n",
    "\n",
    "def analize(raw: Nim) -> dict:\n",
    "    cooked = dict()\n",
    "    cooked[\"possible_moves\"] = dict()\n",
    "\n",
    "    # for each possible move\n",
    "    for ply in (Nimply(r, o) for r, c in enumerate(raw.rows) for o in range(1, c + 1)):\n",
    "        # copy the object\n",
    "        tmp = deepcopy(raw)\n",
    "\n",
    "        # apply the move\n",
    "        tmp.nimming(ply)\n",
    "\n",
    "        # compute the nim sum and store it into the dictionary\n",
    "        cooked[\"possible_moves\"][ply] = nim_sum(tmp)\n",
    "        print(\"Cooked:\", type(cooked[\"possible_moves\"][ply]))\n",
    "\n",
    "    # return the dictionary with the \"score\" obtained by each move\n",
    "    return cooked\n",
    "\n",
    "# basically the optimal strategy consists in picking a random move from the ones with nim sum != 0\n",
    "# it's like a \"try to not lose in this turn\" strategy\n",
    "def optimal(state: Nim) -> Nimply:\n",
    "    # analyze the actual state\n",
    "    analysis = analize(state)\n",
    "    logging.debug(f\"analysis:\\n{pformat(analysis)}\")\n",
    "\n",
    "    # create a list of the moves with nim sum != 0 (with moves with nim sum == 0 we lose)\n",
    "    spicy_moves = [ply for ply, ns in analysis[\"possible_moves\"].items() if ns != 0]\n",
    "\n",
    "    # if there are no spicy moves, we lose, so we pick a random move\n",
    "    if not spicy_moves:\n",
    "        spicy_moves = list(analysis[\"possible_moves\"].keys())\n",
    "\n",
    "    # pick a random spicy move\n",
    "    ply = random.choice(spicy_moves)\n",
    "    # print(\"Ciao\" , type(ply))\n",
    "    return ply   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_GENERATIONS = 100\n",
    "POPULATION_SIZE = 20\n",
    "TOURNAMENT_SIZE = 10\n",
    "GAME_SIZE = 5\n",
    "STARTING_PLAYER = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_valid_moves(state: Nim) -> list:\n",
    "    valid_moves = []\n",
    "\n",
    "    # for row, count in enumerate(state.rows):\n",
    "    #     for k in range(1, count + 1):\n",
    "    #         valid_moves.append(Nimply(row, k))\n",
    "    \n",
    "    for ply in (Nimply(row, k) for row, count in enumerate(state.rows) for k in range(1, count + 1)):\n",
    "        tmp = deepcopy(state)\n",
    "        tmp.nimming(ply)\n",
    "        # if nim_sum(tmp) != 0:\n",
    "        valid_moves.append(ply)\n",
    "    return valid_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prova = Nim(3)\n",
    "# print(prova.rows)\n",
    "\n",
    "# valid_moves = get_valid_moves(prova)\n",
    "# print(valid_moves)\n",
    "# print(type(valid_moves))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a random strategy that picks a random move from the valid ones\n",
    "def create_random_strategy() -> callable:\n",
    "    def random_strategy(valid_moves) -> Nimply:\n",
    "        return random.choice(valid_moves)\n",
    "    return random_strategy\n",
    "\n",
    "# I can \"use\" a strategy by calling it with the valid moves -> strategy(valid_moves)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a population is a list of strategies\n",
    "# a strategy is a function that takes a list of valid moves and returns a move\n",
    "def create_initial_population() -> list:\n",
    "    population = []\n",
    "    for _ in range(POPULATION_SIZE):\n",
    "        population.append(create_random_strategy())\n",
    "    return population\n",
    "\n",
    "# population = [create_random_strategy(), create_random_strategy(), ..., create_random_strategy()]\n",
    "# create_random_strategy() = random_strategy(valid_moves) = random.choice(valid_moves)\n",
    "\n",
    "# a population of strategies consists in a list of strategies, that are objects (of type function) that take a list of valid moves and return a random one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_strategy(strategy: callable, state: Nim) -> int:\n",
    "    score = 0\n",
    "    opponents = (strategy, optimal)\n",
    "    player = STARTING_PLAYER\n",
    "    for _ in range(TOURNAMENT_SIZE):\n",
    "        game = Nim(GAME_SIZE)\n",
    "        while game:\n",
    "            ply = opponents[game]\n",
    "            game.nimming(ply)\n",
    "            player = 1 - player\n",
    "        if player == STARTING_PLAYER:\n",
    "            score += 1\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crossover(mother: Nim, father: Nim) -> Nim:\n",
    "    def new_strategy(valid_moves: list) -> Nimply:\n",
    "        if random.random() < 0.5:\n",
    "            return mother(valid_moves)\n",
    "        else:\n",
    "            return father(valid_moves)\n",
    "    return new_strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def next_generation(population: list, state: Nim) -> list:\n",
    "    new_population = []\n",
    "    scores = []\n",
    "    scores = [(evaluate_strategy(strategy, state), strategy) for strategy in population]\n",
    "    for strategy in population: # population is a list of callables (functions)\n",
    "        score = (evaluate_strategy(strategy, state), strategy)\n",
    "        scores.append(score)\n",
    "    scores.sort(reverse=True)\n",
    "    selected_strategies = [strategy for _, strategy in scores[POPULATION_SIZE // 2]] # select the best half of the population\n",
    "    while len(new_population) < POPULATION_SIZE:\n",
    "        father = random.choice(selected_strategies)\n",
    "        mother = random.choice(selected_strategies)\n",
    "        new_strategy = crossover(father, mother)\n",
    "        new_population.append(new_strategy)\n",
    "    return new_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_best_move() -> Nimply:\n",
    "    return 0\n",
    "\n",
    "def genetic_strategy(state: Nim) -> Nimply:\n",
    "    population = create_initial_population()\n",
    "    valid_moves = get_valid_moves()\n",
    "    for _ in range(NUMBER_OF_GENERATIONS):\n",
    "        population = next_generation(population, valid_moves)\n",
    "    best_move = select_best_move()\n",
    "    return best_move\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticAgent:\n",
    "    def __init__(self, population_size, generations):\n",
    "        self.population_size = population_size\n",
    "        self.generations = generations\n",
    "\n",
    "\n",
    "    # def get_valid_moves(self, state):\n",
    "    #     valid_moves = []\n",
    "    #     for r, c in enumerate(state.rows):\n",
    "    #         for o in range(1, c + 1):\n",
    "    #             valid_moves.append(Nimply(r, o))\n",
    "    #     return valid_moves\n",
    "\n",
    "    def get_valid_moves(self, state: Nim):\n",
    "        # create an empty list\n",
    "        valid_moves = []\n",
    "        for ply in (Nimply(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)):\n",
    "            # yield ply\n",
    "            tmp = deepcopy(state)\n",
    "            tmp.nimming(ply)\n",
    "            nimsum = nim_sum(tmp)\n",
    "            if nim_sum != 0:\n",
    "                valid_moves.append(nimsum)\n",
    "        return valid_moves\n",
    "\n",
    "    def evolve(self, state: Nim):\n",
    "        population = self.create_initial_population()\n",
    "        # valid_moves = state.get_valid_moves()\n",
    "        valid_moves = self.get_valid_moves(state)\n",
    "        print(\"ciao\", type(valid_moves))\n",
    "        for _ in range(self.generations):\n",
    "            print(type(valid_moves))\n",
    "            population = self.next_generation(population, valid_moves)\n",
    "        return self.select_best_move(population, state)\n",
    "\n",
    "    def create_initial_population(self):\n",
    "        population = []\n",
    "        for _ in range(self.population_size):\n",
    "            population.append(self.create_random_strategy())\n",
    "        return population\n",
    "\n",
    "    def create_random_strategy(self):\n",
    "        def random_strategy(valid_moves):\n",
    "            return random.choice(valid_moves)\n",
    "        return random_strategy\n",
    "\n",
    "    def evaluate_strategy(self, strategy: Nim, state: Nim):\n",
    "        # Evaluate the strategy by playing multiple games and obtaining a score based on performance\n",
    "        score = 0\n",
    "        for _ in range(10):  # Play 10 games to evaluate strategy\n",
    "            new_state = deepcopy(state)\n",
    "            # print(type(state))\n",
    "            move = strategy(new_state)  # Get a move from the strategy\n",
    "            \n",
    "            # print(move)\n",
    "            new_state.nimming(move)  # Apply the move to the state\n",
    "            # Update score based on the result of the game\n",
    "            # Here you can define how to score the performance based on wins or losses\n",
    "            # For example, increment score if the strategy wins the game\n",
    "            if new_state.__bool__():\n",
    "                score += 1\n",
    "        return score\n",
    "\n",
    "    def next_generation(self, population, state: Nim):\n",
    "\n",
    "        scores = [(self.evaluate_strategy(strategy, state), strategy) for strategy in population]\n",
    "        scores.sort(reverse=True)  # Sort strategies by their scores\n",
    "        selected_strategies = [strategy for _, strategy in scores[:self.population_size // 2]]\n",
    "        print(type(state))\n",
    "        new_population = []\n",
    "        while len(new_population) < self.population_size:\n",
    "            parent1 = random.choice(selected_strategies)\n",
    "            parent2 = random.choice(selected_strategies)\n",
    "            new_strategy = self.crossover(parent1, parent2)\n",
    "            new_population.append(new_strategy)\n",
    "        return new_population\n",
    "\n",
    "    def crossover(self, strategy1, strategy2):\n",
    "        def new_strategy(board, valid_moves):\n",
    "            if random.random() < 0.5:\n",
    "                return strategy1(board, valid_moves)\n",
    "            else:\n",
    "                return strategy2(board, valid_moves)\n",
    "        return new_strategy\n",
    "\n",
    "    def select_best_move(self, population, state: Nim):\n",
    "        scores = [(self.evaluate_strategy(strategy, state), strategy) for strategy in population]\n",
    "        best_strategy = max(scores, key=lambda x: x[0])[1]\n",
    "        return best_strategy\n",
    "\n",
    "# Replace `genetic` with an instance of `GeneticAgent`\n",
    "genetic = GeneticAgent(population_size=20, generations=50)\n",
    "\n",
    "# Define the rest of your code and call `genetic.evolve(state)` where you wish to make the agent select its move.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:init : <1 3 5 7>\n",
      "INFO:root:ply: player 0 plays Nimply(row=0, num_objects=1)\n",
      "INFO:root:status: <0 3 5 7>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "ciao <class 'list'>\n",
      "<class 'list'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'nimming'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m     ply \u001b[38;5;241m=\u001b[39m optimal(nim)  \u001b[38;5;66;03m# Giocatore 0 utilizza la strategia ottimale\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     ply \u001b[38;5;241m=\u001b[39m \u001b[43mgenetic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnim\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Giocatore 1 utilizza la strategia evoluta dall'agente genetico\u001b[39;00m\n\u001b[1;32m     15\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mply: player \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m plays \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mply\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m nim\u001b[38;5;241m.\u001b[39mnimming(ply)\n",
      "Cell \u001b[0;32mIn[53], line 33\u001b[0m, in \u001b[0;36mGeneticAgent.evolve\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerations):\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(valid_moves))\n\u001b[0;32m---> 33\u001b[0m     population \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_moves\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect_best_move(population, state)\n",
      "Cell \u001b[0;32mIn[53], line 66\u001b[0m, in \u001b[0;36mGeneticAgent.next_generation\u001b[0;34m(self, population, state)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnext_generation\u001b[39m(\u001b[38;5;28mself\u001b[39m, population, state: Nim):\n\u001b[0;32m---> 66\u001b[0m     scores \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_strategy(strategy, state), strategy) \u001b[38;5;28;01mfor\u001b[39;00m strategy \u001b[38;5;129;01min\u001b[39;00m population]\n\u001b[1;32m     67\u001b[0m     scores\u001b[38;5;241m.\u001b[39msort(reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Sort strategies by their scores\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     selected_strategies \u001b[38;5;241m=\u001b[39m [strategy \u001b[38;5;28;01mfor\u001b[39;00m _, strategy \u001b[38;5;129;01min\u001b[39;00m scores[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m]]\n",
      "Cell \u001b[0;32mIn[53], line 66\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnext_generation\u001b[39m(\u001b[38;5;28mself\u001b[39m, population, state: Nim):\n\u001b[0;32m---> 66\u001b[0m     scores \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m, strategy) \u001b[38;5;28;01mfor\u001b[39;00m strategy \u001b[38;5;129;01min\u001b[39;00m population]\n\u001b[1;32m     67\u001b[0m     scores\u001b[38;5;241m.\u001b[39msort(reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Sort strategies by their scores\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     selected_strategies \u001b[38;5;241m=\u001b[39m [strategy \u001b[38;5;28;01mfor\u001b[39;00m _, strategy \u001b[38;5;129;01min\u001b[39;00m scores[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m]]\n",
      "Cell \u001b[0;32mIn[53], line 56\u001b[0m, in \u001b[0;36mGeneticAgent.evaluate_strategy\u001b[0;34m(self, strategy, state)\u001b[0m\n\u001b[1;32m     53\u001b[0m move \u001b[38;5;241m=\u001b[39m strategy(new_state)  \u001b[38;5;66;03m# Get a move from the strategy\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# print(move)\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m \u001b[43mnew_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnimming\u001b[49m(move)  \u001b[38;5;66;03m# Apply the move to the state\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Update score based on the result of the game\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Here you can define how to score the performance based on wins or losses\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# For example, increment score if the strategy wins the game\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_state\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__bool__\u001b[39m():\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'nimming'"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "nim = Nim(4)\n",
    "logging.info(f\"init : {nim}\")\n",
    "\n",
    "genetic = GeneticAgent(population_size=20, generations=50)  # Istanzia l'agente genetico\n",
    "\n",
    "player = 0\n",
    "while nim:\n",
    "    if player == 0:\n",
    "        ply = optimal(nim)  # Giocatore 0 utilizza la strategia ottimale\n",
    "    else:\n",
    "        ply = genetic.evolve(nim)  # Giocatore 1 utilizza la strategia evoluta dall'agente genetico\n",
    "\n",
    "    logging.info(f\"ply: player {player} plays {ply}\")\n",
    "    nim.nimming(ply)\n",
    "    logging.info(f\"status: {nim}\")\n",
    "    player = 1 - player\n",
    "\n",
    "logging.info(f\"status: Player {player} won!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversimplified match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:init : <1 3 5 7>\n",
      "INFO:root:ply: player 0 plays Nimply(row=3, num_objects=3)\n",
      "INFO:root:status: <1 3 5 4>\n",
      "INFO:root:ply: player 1 plays Nimply(row=0, num_objects=1)\n",
      "INFO:root:status: <0 3 5 4>\n",
      "INFO:root:ply: player 0 plays Nimply(row=2, num_objects=2)\n",
      "INFO:root:status: <0 3 3 4>\n",
      "INFO:root:ply: player 1 plays Nimply(row=2, num_objects=2)\n",
      "INFO:root:status: <0 3 1 4>\n",
      "INFO:root:ply: player 0 plays Nimply(row=1, num_objects=3)\n",
      "INFO:root:status: <0 0 1 4>\n",
      "INFO:root:ply: player 1 plays Nimply(row=3, num_objects=2)\n",
      "INFO:root:status: <0 0 1 2>\n",
      "INFO:root:ply: player 0 plays Nimply(row=2, num_objects=1)\n",
      "INFO:root:status: <0 0 0 2>\n",
      "INFO:root:ply: player 1 plays Nimply(row=3, num_objects=1)\n",
      "INFO:root:status: <0 0 0 1>\n",
      "INFO:root:ply: player 0 plays Nimply(row=3, num_objects=1)\n",
      "INFO:root:status: <0 0 0 0>\n",
      "INFO:root:status: Player 1 won!\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "# define the two players\n",
    "strategy = (optimal, pure_random)\n",
    "\n",
    "nim = Nim(4)\n",
    "logging.info(f\"init : {nim}\")\n",
    "\n",
    "# first player to move is player 0\n",
    "player = 0\n",
    "while nim:\n",
    "    ply = strategy[player](nim)\n",
    "    logging.info(f\"ply: player {player} plays {ply}\")\n",
    "    nim.nimming(ply)\n",
    "    logging.info(f\"status: {nim}\")\n",
    "    player = 1 - player\n",
    "logging.info(f\"status: Player {player} won!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('ci22-dPIXJ0_o-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "10197e8e2f2aa67e2c349105091c77f4cd384fce4877865f002d9ec653f96bc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
