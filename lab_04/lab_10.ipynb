{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from collections import namedtuple, defaultdict\n",
    "from random import choice\n",
    "from copy import deepcopy\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem : Reinforcement Learning for Tic-Tac-Toe Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, to develop a reinforcement learning algorithm, we need to define the following components:\n",
    "* **Environment** \n",
    "  * Possible states in the game environment\n",
    "  * Possible actions in each state\n",
    "  * Rewards for each action in each state\n",
    "\n",
    "* **Agent**\n",
    "  * Policy: the strategy to choose an action given a state\n",
    "  * Value function: the expected return of each state under a given policy\n",
    "  * Model: the agent's representation of the environment\n",
    "\n",
    "* **Learning Algorithm**\n",
    "  * How the agent updates its policy and value function based on the experience\n",
    "\n",
    "In this problem, we will implement a reinforcement learning algorithm for the Tic-Tac-Toe game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State is a namedtuple with two fields, x and o, representing the positions of X and O in the board.\n",
    "\n",
    "MAGIC is a list of values that can be used to check whether a player has won the game. They are based on the magic square of order 3.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>2</td>\n",
    "    <td>7</td>\n",
    "    <td>6</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>9</td>\n",
    "    <td>5</td>\n",
    "    <td>1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>4</td>\n",
    "    <td>3</td>\n",
    "    <td>8</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "In this way, the sum of three numbers in any row, column, or diagonal is always 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "State = namedtuple('State', ['x', 'o'])\n",
    "MAGIC = [2, 7, 6, 9, 5, 1, 4, 3, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stolen from quixo repo\n",
    "class Player(ABC):\n",
    "    def __init__(self) -> None:\n",
    "        '''You can change this for your player if you need to handle state/have memory'''\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def make_move(self):\n",
    "        '''\n",
    "        game: the Quixo game. You can use it to override the current game with yours, but everything is evaluated by the main game\n",
    "        return values: this method shall return a tuple of X,Y positions and a move among TOP, BOTTOM, LEFT and RIGHT\n",
    "        '''\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "    def __init__(self):\n",
    "        self.state = State(set(), set()) # actual state of the game\n",
    "        self.trajectory = list() # list of states of the game\n",
    "        self.available_moves = set(range(1, 10)) # available moves\n",
    "        self.winner = None # winner of the game\n",
    "\n",
    "    def play(self, player1, player2):\n",
    "        \"\"\"Play a game between two players\"\"\"\n",
    "        print(\"available moves: \", self.available_moves)\n",
    "        local_winner = -1\n",
    "        while local_winner == -1 and len(self.available_moves) > 0:\n",
    "            # player1 makes a move\n",
    "            move = player1.make_move(self.state, self.available_moves)\n",
    "            print(\"player1 move: \", move)\n",
    "\n",
    "            # the move is added to the state\n",
    "            self.state.x.add(move)\n",
    "\n",
    "            # the move is removed from the available moves\n",
    "            self.available_moves.remove(move)\n",
    "            print(\"available moves: \", self.available_moves)\n",
    "\n",
    "            # check if the game is over\n",
    "            local_winner = self.check_winner()\n",
    "            if local_winner != -1 or len(self.available_moves) == 0:\n",
    "                break\n",
    "\n",
    "            # same for player2\n",
    "            move = player2.make_move(self.state, self.available_moves)\n",
    "            print(\"player2 move: \", move)\n",
    "            self.state.o.add(move)\n",
    "            self.available_moves.remove(move)\n",
    "            print(\"available moves: \", self.available_moves)\n",
    "            local_winner = self.check_winner()\n",
    "            if local_winner != -1 or len(self.available_moves) == 0:\n",
    "                break\n",
    "\n",
    "        self.winner = local_winner\n",
    "        print(\"winner: \", self.winner)\n",
    "\n",
    "    def check_winner(self):\n",
    "        \"\"\"Set the winner: 1 for player1, 2 for player2, -1 for draw\"\"\"\n",
    "        if self.win(self.state.x):\n",
    "            return 1\n",
    "        elif self.win(self.state.o):\n",
    "            return 2\n",
    "        else:\n",
    "            return -1\n",
    "        \n",
    "    # win() function checks if any of the combinations of 3 elements in the set sums to 15 (winning condition)\n",
    "    def win(self, elements):\n",
    "        \"\"\"Checks if elements is winning\"\"\"\n",
    "        return any(sum(c) == 15 for c in combinations(elements, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defaultdict is a subclass of dict that returns a default value when the key is not found, so that it is not needed to check whether a key is in the dictionary.\n",
    "\n",
    "frozenset is an immutable version of set, which can be used as a key in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_dictionary = defaultdict(float) # state of the game and its value\n",
    "hit_state = defaultdict(int) # state of the game and how many times it was visited during the training phase\n",
    "epsilon = 0.001\n",
    "\n",
    "for steps in tqdm(range(500_000)):\n",
    "    trajectory = random_game()\n",
    "    final_reward = state_value(trajectory[-1])\n",
    "    for state in trajectory:\n",
    "        hashable_state = (frozenset(state.x), frozenset(state.o))\n",
    "        hit_state[hashable_state] += 1\n",
    "        value_dictionary[hashable_state] = value_dictionary[\n",
    "            hashable_state\n",
    "        ] + epsilon * (final_reward - value_dictionary[hashable_state])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPlayer(Player):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def make_move(self, state, available_moves):\n",
    "        return choice(list(available_moves))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class reinforcement_player():\n",
    "    def __init__(self):\n",
    "        self.value_dictionary = defaultdict(float) # state of the game and its value\n",
    "        self.states = list() # list of states visited during the game, used to update the value_dictionary\n",
    "        self.hit_state = defaultdict(int) # state of the game and how many times it was visited during the training phase\n",
    "        self.epsilon = 0.001 # learning rate\n",
    "\n",
    "    def make_move(self, state):\n",
    "        \"\"\"Returns best move for state\"\"\"\n",
    "        hashable_state = (frozenset(state.x), frozenset(state.o))\n",
    "        possible_moves = set(range(1, 10)) - set(state.x + state.o)\n",
    "        possible_states = [\n",
    "            State(state.x + [move], state.o) for move in possible_moves\n",
    "        ]\n",
    "        possible_values = [\n",
    "            self.value_dictionary[(frozenset(s.x), frozenset(s.o))]\n",
    "            for s in possible_states\n",
    "        ]\n",
    "        return possible_states[np.argmax(possible_values)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available moves:  {1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
      "player1 move:  6\n",
      "available moves:  {1, 2, 3, 4, 5, 7, 8, 9}\n",
      "player2 move:  7\n",
      "available moves:  {1, 2, 3, 4, 5, 8, 9}\n",
      "player1 move:  9\n",
      "available moves:  {1, 2, 3, 4, 5, 8}\n",
      "player2 move:  8\n",
      "available moves:  {1, 2, 3, 4, 5}\n",
      "player1 move:  3\n",
      "available moves:  {1, 2, 4, 5}\n",
      "player2 move:  1\n",
      "available moves:  {2, 4, 5}\n",
      "player1 move:  2\n",
      "available moves:  {4, 5}\n",
      "player2 move:  5\n",
      "available moves:  {4}\n",
      "player1 move:  4\n",
      "available moves:  set()\n",
      "winner:  1\n"
     ]
    }
   ],
   "source": [
    "test_game = Game()\n",
    "player1 = RandomPlayer()\n",
    "player2 = RandomPlayer()\n",
    "test_game.play(player1, player2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Computational_Intelligence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
