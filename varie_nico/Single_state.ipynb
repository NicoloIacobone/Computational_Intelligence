{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random, choice, randint\n",
    "from functools import reduce\n",
    "from collections import namedtuple\n",
    "from queue import PriorityQueue, SimpleQueue, LifoQueue\n",
    "from copy import copy, deepcopy\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBLEM_SIZE = 1_000\n",
    "NUM_SETS = 5_000\n",
    "SETS = tuple(np.array([random() < 0.3 for _ in range(PROBLEM_SIZE)]) for _ in range(NUM_SETS))\n",
    "State = namedtuple('State', ['taken', 'not_taken'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness1(state):\n",
    "    cost = sum(state)\n",
    "    valid = np.all(\n",
    "        reduce(\n",
    "            np.logical_or,\n",
    "            [SETS[i] for i, t in enumerate(state) if t],\n",
    "            np.array([False for _ in range(PROBLEM_SIZE)]),\n",
    "        )\n",
    "    )\n",
    "    return valid, -cost\n",
    "\n",
    "def fitness2(state):\n",
    "    cost = sum(state)\n",
    "    valid = np.sum(\n",
    "        reduce(\n",
    "            np.logical_or,\n",
    "            [SETS[i] for i, t in enumerate(state) if t],\n",
    "            np.array([False for _ in range(PROBLEM_SIZE)]),\n",
    "        )\n",
    "    )\n",
    "    return valid, -cost\n",
    "\n",
    "def fitness3(state):\n",
    "    return sum(state)\n",
    "\n",
    "fitness = fitness3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweak(state):\n",
    "    new_state = copy(state)\n",
    "    index = randint(0, PROBLEM_SIZE - 1)\n",
    "    new_state[index] = not new_state[index]\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-State Methods\n",
    "\n",
    "They are used to find local best solutions.\n",
    "\n",
    "### General procedure\n",
    "- **Initialization**: choose a starting candidate solution\n",
    "- **Evaluation**: evaluate the quality of the current solution using the `objective or fitness_function`\n",
    "- **Modification**: `tweak` the current solution to obtain a new candidate solution (modify it a little bit)\n",
    "- **Selection**: choose which candidate solution to keep\n",
    "- **Termination**: stop when a termination criterion is met\n",
    "  - Maximum number of iterations\n",
    "  - Maximum number of evaluations\n",
    "  - Wall-clock time\n",
    "  - Quality threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweaking\n",
    "\n",
    "Optimization algorithms define specific `tweak operators` tailored to the problem. These operators dictate how to modify solutions, such as:\n",
    "- swapping elements\n",
    "- adjusting values\n",
    "- applying random noise\n",
    "\n",
    "üîé **Exploitation**: make small adjustments to the current solution to improve it\n",
    "1. *Adjust the modification procedure*, usually making a `small tweak` to the current solution\n",
    "2. *Use a larger sample*, exploring a larger region of the search space (`neighborhood`) at each step\n",
    "  \n",
    "üó∫Ô∏è **Exploration**: make large adjustments to explore a different region of the search space\n",
    "\n",
    "1. *Adjust the modification procedure*, occasionally making a `big tweak` to explore a different region of the search space\n",
    "2. *Adjust the selection procedure*, occasionally accept a `worse solution` to avoid getting stuck in a local optimum\n",
    "3. *Jump to sth new*, restarting the algorithm from a `different random starting point` to explore a different region of the search space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hill-Climbing\n",
    "\n",
    "* `Random Mutation HC`: It just iteratively test new candidate solutions in the region of the current candidate, and adopt the new ones if they're better.\n",
    "* `Steepest ascent HC`: it generates multiple \"tweaks\" to a candidate solution simultaneously, and then it selects the best-performing one for adoption.\n",
    "* `Random-restart HC`: In order to avoid getting stuck in a local optimum, we can restart the algorithm from a different random starting point. Note that we're just increasing the probability of finding the global optimum, but we're not guaranteed to find it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mutation_hc(problem, max_iterations):\n",
    "    number_iterations = 0\n",
    "\n",
    "    # Loop until we reach the maximum number of iterations\n",
    "    for _ in range(max_iterations):\n",
    "        number_iterations += 1\n",
    "        actual_state = deepcopy(problem)\n",
    "        next_state = tweak(problem)\n",
    "\n",
    "        if(fitness(next_state) > fitness(actual_state)):\n",
    "            problem = next_state\n",
    "\n",
    "            # If we have reached a satisfactory solution, stop\n",
    "            if(fitness(problem) == PROBLEM_SIZE):\n",
    "                break\n",
    "\n",
    "    return problem, number_iterations\n",
    "\n",
    "def steepest_ascend_hc(problem, max_iterations, neighbours_size):\n",
    "    number_iterations = 0\n",
    "\n",
    "    # Loop until we reach the maximum number of iterations\n",
    "    for _ in range(max_iterations):\n",
    "        number_iterations += 1\n",
    "        actual_state = deepcopy(problem)\n",
    "        \n",
    "        # Get all the neighbours\n",
    "        neighbours = [tweak(problem) for _ in range(neighbours_size)]\n",
    "        best_neighbour = max(neighbours, key=fitness)\n",
    "        if(fitness(best_neighbour) > fitness(actual_state)):\n",
    "            problem = best_neighbour\n",
    "\n",
    "            # If we have reached a satisfactory solution, stop\n",
    "            if(fitness(problem) == PROBLEM_SIZE):\n",
    "                break\n",
    "\n",
    "    return problem, number_iterations\n",
    "\n",
    "def random_restart_hc(max_iterations, restarts):\n",
    "    best_solution = None\n",
    "    number_of_restarts = 0\n",
    "\n",
    "    # Loop until we reach the maximum number or restarts\n",
    "    for _ in range(restarts):\n",
    "        problem = np.array([choice([True, False, False, False, False]) for _ in range(PROBLEM_SIZE)])\n",
    "        number_of_restarts += 1\n",
    "        problem, _ = random_mutation_hc(problem, max_iterations)\n",
    "\n",
    "        if(best_solution is None or fitness(problem) > fitness(best_solution)):\n",
    "            best_solution = problem\n",
    "\n",
    "        # If we have reached a satisfactory solution, stop\n",
    "        if(fitness(problem) == PROBLEM_SIZE):\n",
    "            break\n",
    "\n",
    "    return best_solution, number_of_restarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####Random Mutation Hill Climbing####\n",
      "original problem fitness:\t 0\n",
      "solved problem fitness:\t\t 1000\n",
      "iterations:\t\t\t 6078\n",
      "---------------------------------------\n",
      "\n",
      "####Steepest Ascend Hill Climbing####\n",
      "original problem fitness:\t 0\n",
      "solved problem fitness:\t\t 1000\n",
      "iterations:\t\t\t 1328\n",
      "---------------------------------------\n",
      "\n",
      "####Random Restart Hill Climbing####\n",
      "original problem fitness:\t 0\n",
      "solved problem fitness:\t\t 1000\n",
      "restarts:\t\t\t 2\n",
      "---------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "problem = np.array([False for _ in range(PROBLEM_SIZE)])\n",
    "solved_problem_rm, iterations_rm = random_mutation_hc(problem, 10000)\n",
    "solved_problem_sa, iterations_sa = steepest_ascend_hc(problem, 10000, 15)\n",
    "solved_problem_rr, iterations_rr = random_restart_hc(6500, 10)\n",
    "\n",
    "print(\"####Random Mutation Hill Climbing####\")\n",
    "print(\"original problem fitness:\\t\", fitness(problem))\n",
    "print(\"solved problem fitness:\\t\\t\", fitness(solved_problem_rm))\n",
    "print(\"iterations:\\t\\t\\t\", iterations_rm)\n",
    "print(\"---------------------------------------\\n\")\n",
    "\n",
    "print(\"####Steepest Ascend Hill Climbing####\")\n",
    "print(\"original problem fitness:\\t\", fitness(problem))\n",
    "print(\"solved problem fitness:\\t\\t\", fitness(solved_problem_sa))\n",
    "print(\"iterations:\\t\\t\\t\", iterations_sa)\n",
    "print(\"---------------------------------------\\n\")\n",
    "\n",
    "print(\"####Random Restart Hill Climbing####\")\n",
    "print(\"original problem fitness:\\t\", fitness(problem))\n",
    "print(\"solved problem fitness:\\t\\t\", fitness(solved_problem_rr))\n",
    "print(\"restarts:\\t\\t\\t\", iterations_rr)\n",
    "print(\"---------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated-Annealing\n",
    "\n",
    "This technique is based on performing exploration, and then exploitation, based on an hyperparameter, the temperature, that allows to accept a worse candidate solution with a certain probability.\n",
    "This is useful to escape from local minima\n",
    "\n",
    "The probability of accepting a new candidate solution is defined by the `Boltzmann distribution`:\n",
    "- $S$ = current solution\n",
    "- $R$ = new candidate solution\n",
    "- $t$ = current temperature\n",
    "- $c$ = cooling rate $\\in [0,1]$ that defines how fast the temperature decreases\n",
    "\n",
    "$P(R|S,t) = e^{\\frac{Quality(R)-Quality(S)}{t}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_annealing(problem, temperature, cooling_rate, max_iterations):\n",
    "    number_iterations = 0\n",
    "\n",
    "    # Loop until we reach the maximum number of iterations\n",
    "    for _ in range(max_iterations):\n",
    "        number_iterations += 1\n",
    "        actual_state = deepcopy(problem)\n",
    "        next_state = tweak(problem)\n",
    "\n",
    "        if(fitness(next_state) > fitness(actual_state)):\n",
    "            problem = next_state\n",
    "\n",
    "            # If we have reached a satisfactory solution, stop\n",
    "            if(fitness(problem) == PROBLEM_SIZE):\n",
    "                break\n",
    "        else:\n",
    "            # Calculate the probability of accepting the worse solution\n",
    "            probability = np.exp((fitness(next_state) - fitness(actual_state)) / temperature)\n",
    "\n",
    "            if(random() < probability):\n",
    "                problem = next_state\n",
    "\n",
    "        # Cool the temperature\n",
    "        temperature *= cooling_rate\n",
    "\n",
    "        # If the temperature is too low, stop\n",
    "        if(temperature < 1e-15):\n",
    "            break\n",
    "\n",
    "    return problem, number_iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####Simulated Annealing####\n",
      "original problem fitness:\t 0\n",
      "solved problem fitness:\t\t 1000\n",
      "iterations:\t\t\t 9446\n",
      "---------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "solved_problem_ann, iterations_ann = simulated_annealing(problem, 100, 0.999, 10000)\n",
    "\n",
    "print(\"####Simulated Annealing####\")\n",
    "print(\"original problem fitness:\\t\", fitness(problem))\n",
    "print(\"solved problem fitness:\\t\\t\", fitness(solved_problem_ann))\n",
    "print(\"iterations:\\t\\t\\t\", iterations_ann)\n",
    "print(\"---------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabu search\n",
    "Tabu search is a popular metaheuristic that guides a local search procedure to explore the search space beyond the local optimum.\n",
    "\n",
    "> üôÖüèª‚Äç‚ôÄÔ∏è It is based on the idea of `forbidding` the algorithm to visit the same state twice, i.e. it keeps track of the visited states in a `tabu list` and avoids them for a certain number of iterations.\n",
    "\n",
    "It is particularly effective in solving *combinatorial optimization problems*, where the goal is to find the best solution from a finite set of possibilities. But really only works well when the search space is discrete and finite.\n",
    "- ‚ö†Ô∏è If the search space is continuous or infinite, only in truly and exceptionally rare cases will the algorithm ever visit the same state twice! In this case, we should check if the current solution is *sufficiently similar* to a previously visited one, and then decide whether to forbid it or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabu_search(problem, max_iterations):\n",
    "    number_iterations = 0\n",
    "    tabu_list = []\n",
    "\n",
    "    # Loop until we reach the maximum number of iterations\n",
    "    for _ in range(max_iterations):\n",
    "        number_iterations += 1\n",
    "        actual_state = deepcopy(problem)\n",
    "        next_state = tweak(problem)\n",
    "\n",
    "        if(fitness(next_state) > fitness(actual_state)):\n",
    "            problem = next_state\n",
    "\n",
    "            # If we have reached a satisfactory solution, stop\n",
    "            if(fitness(problem) == PROBLEM_SIZE):\n",
    "                break\n",
    "        else:\n",
    "            # If the next state is in the tabu list, skip it\n",
    "            if(fitness(next_state) in tabu_list):\n",
    "                continue\n",
    "\n",
    "            problem = next_state\n",
    "\n",
    "        # Add the actual state to the tabu list\n",
    "        tabu_list.append(fitness(actual_state))\n",
    "    return problem, number_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####Tabu Search####\n",
      "original problem fitness:\t 0\n",
      "solved problem fitness:\t\t 1000\n",
      "iterations:\t\t\t 8602\n",
      "---------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "solved_problem_tabu, iterations_tabu = tabu_search(problem, 10000)\n",
    "\n",
    "print(\"####Tabu Search####\")\n",
    "print(\"original problem fitness:\\t\", fitness(problem))\n",
    "print(\"solved problem fitness:\\t\\t\", fitness(solved_problem_tabu))\n",
    "print(\"iterations:\\t\\t\\t\", iterations_tabu)\n",
    "print(\"---------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterated local search\n",
    "Iterated local search is a metaheuristic that combines a local search procedure with a perturbation mechanism to escape local optima, and it is essentially a smarter version of random-restart hill climbing.\n",
    "\n",
    "> It tries to stochasticly hill climb in the space of local optima. To do so, it uses a `home base` solution, which is the best solution found so far, and a `perturbation operator` perform a *just large enough jump* to escape this local optimum and land in a different region of the search space. ‚õ∞Ô∏è<--üèÉüèª‚Äç‚ôÇÔ∏è--üè°\n",
    "\n",
    "1. Hill climbing is used iteratively for a maximum number of iterations to find a local optimum \n",
    "2. If the new local optimum is better than the current home base, it becomes the new home base\n",
    "3. The perturbation operator is designed to be substantial enough to likely jump to a new region of the solution space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Computational_Intelligence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
