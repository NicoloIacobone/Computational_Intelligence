{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_players import ReinforcementPlayer\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "reinforcement_player = ReinforcementPlayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_policy(self, policy_file):\n",
    "    \"\"\"Loads the policy file\"\"\"\n",
    "    fr = open(policy_file, 'rb')\n",
    "    self.value_dictionary = pickle.load(fr)\n",
    "    fr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_policy(reinforcement_player, \"policies/final_policies/policy_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13477063\n"
     ]
    }
   ],
   "source": [
    "print(len(reinforcement_player.value_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "reinforcement_player.create_policy(\"policies/only_gzip_compression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_value_dictionary = defaultdict(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_hash(board):\n",
    "    # Transform the original values of the board to their binary representation\n",
    "    mapping = {255: '00', 0: '01', 1: '10'}\n",
    "    # Then, for each row, for each column, each value is appended to create a single string\n",
    "    binary_string = ''.join(mapping[val] for row in board for val in row)\n",
    "\n",
    "    # convert the binary string to an integer\n",
    "    return int(binary_string, 2)\n",
    "\n",
    "def my_undo_hash(compact_hash, shape=(5, 5)):\n",
    "    # converts the hash into a binary string\n",
    "    binary_string = format(compact_hash, f'0{shape[0] * shape[1] * 2}b')\n",
    "\n",
    "    # Transform the binary string to the original values of the board\n",
    "    mapping = {'00': -1, '01': 0, '10': 1}\n",
    "    # Iterates over binary_string, taking 2 bits at a time and converting them to their original value\n",
    "    values = [mapping[binary_string[i:i+2]] for i in range(0, len(binary_string), 2)]\n",
    "\n",
    "    # Reshape the values to the original shape of the board\n",
    "    return np.array(values).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13477063/13477063 [04:24<00:00, 50965.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# replace all the keys of reinforcement_player.value_dictionary with the keys hashed using my_hash function\n",
    "for key, value in tqdm(reinforcement_player.value_dictionary.items()):\n",
    "    original_key = np.frombuffer(key, dtype=np.uint8).reshape(5, 5)\n",
    "    hashed_key = my_hash(original_key)\n",
    "    test_value_dictionary[hashed_key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13477063\n"
     ]
    }
   ],
   "source": [
    "print(len(test_value_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_reinforcement_player = ReinforcementPlayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_reinforcement_player.value_dictionary = test_value_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13477063\n"
     ]
    }
   ],
   "source": [
    "print(len(new_reinforcement_player.value_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_policy(self, policy_file):\n",
    "    \"\"\"Creates the policy file\"\"\"\n",
    "    fw = open(policy_file, 'wb')\n",
    "    pickle.dump(self.value_dictionary, fw)\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_policy(new_reinforcement_player, \"policies/only_my_hash_function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_reinforcement_player.create_policy(\"policies/zipped_good_policy_cristo_ti_prego\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = Utils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import RandomPlayer, Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_player = RandomPlayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win rate player 1: 93.5%\n",
      "Lose rate player 1: 6.5%\n",
      "Draw rate: 0.0%\n",
      "Average trajectory size: 0.0\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "environment.test(new_reinforcement_player, random_player)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Computational_Intelligence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
